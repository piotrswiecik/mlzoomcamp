{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset\n",
    "\n",
    "data_url = \"https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv\"\n",
    "\n",
    "filename = \"cars_data.csv\"\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    urllib.request.urlretrieve(data_url, filename)\n",
    "\n",
    "df_in = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_clean(df):\n",
    "    \"\"\"\n",
    "    Clean the dataframe - convert column names to lower case and replace spaces \n",
    "    with underscores.\n",
    "    Remove NaNs.\n",
    "    Modifies df in place.\n",
    "    \"\"\"\n",
    "    df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "    \n",
    "    string_columns = df.dtypes[df.dtypes == \"object\"].index\n",
    "\n",
    "    for col in string_columns:\n",
    "        df[col] = df[col].str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "# clean the dataframe\n",
    "df_in  = df_clean(df_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAKES = [\n",
    "            \"chevrolet\",\n",
    "            \"ford\",\n",
    "            \"volkswagen\",\n",
    "            \"toyota\",\n",
    "            \"dodge\",\n",
    "            \"nissan\",\n",
    "            \"gmc\",\n",
    "            \"honda\",\n",
    "            \"mazda\",\n",
    "            \"cadillac\"\n",
    "        ]\n",
    "\n",
    "FUEL_TYPES = list(df_in.engine_fuel_type.unique())\n",
    "\n",
    "TRANSMISSIONS = list(df_in.transmission_type.unique())\n",
    "\n",
    "WD_TYPES = list(df_in.driven_wheels.unique())\n",
    "\n",
    "MARKET_CATEGORIES = list(df_in.market_category.unique())\n",
    "\n",
    "VEHICLE_SIZES = list(df_in.vehicle_size.unique())\n",
    "\n",
    "VEHICLE_STYLES = list(df_in.vehicle_style.unique())\n",
    "\n",
    "def process_features(df):\n",
    "    \"\"\"\n",
    "    Process features - convert categoricals into dummies.\n",
    "    Returns a new dataframe.\n",
    "    \"\"\"\n",
    "    _df = df.copy()\n",
    "\n",
    "    _features = [\"engine_hp\", \"engine_cylinders\", \"highway_mpg\", \"city_mpg\", \"popularity\"]\n",
    "\n",
    "    # add age column\n",
    "    _df[\"age\"] = 2017 - _df.year\n",
    "    _features.append(\"age\")\n",
    "\n",
    "    # convert num doors into dummies\n",
    "    for v in [2, 3, 4]:\n",
    "        _df[f\"num_doors_{v}\"] = (df.number_of_doors == v).astype(int)\n",
    "        _features.append(f\"num_doors_{v}\")\n",
    "\n",
    "    # use 10 most popular makes as dummies\n",
    "    for make in MAKES:\n",
    "        _df[f\"make_{make}\"] = (_df.make == make).astype(int)\n",
    "        _features.append(f\"make_{make}\")\n",
    "\n",
    "    for fuel in FUEL_TYPES:\n",
    "        _df[f\"fuel_{fuel}\"] = (_df.engine_fuel_type == fuel).astype(int)\n",
    "        _features.append(f\"fuel_{fuel}\")\n",
    "\n",
    "    for transmission in TRANSMISSIONS:\n",
    "        _df[f\"transmission_{transmission}\"] = (_df.transmission_type == transmission).astype(int)\n",
    "        _features.append(f\"transmission_{transmission}\")\n",
    "\n",
    "    for wd in WD_TYPES:\n",
    "        _df[f\"wd_{wd}\"] = (_df.driven_wheels == wd).astype(int)\n",
    "        _features.append(f\"wd_{wd}\")\n",
    "\n",
    "    for cat in MARKET_CATEGORIES:\n",
    "        _df[f\"cat_{cat}\"] = (_df.market_category == cat).astype(int)\n",
    "        _features.append(f\"cat_{cat}\")\n",
    "\n",
    "    for s in VEHICLE_SIZES:\n",
    "        _df[f\"size_{s}\"] = (_df.vehicle_size == s).astype(int)\n",
    "        _features.append(f\"size_{s}\")\n",
    "\n",
    "    for s in VEHICLE_STYLES:\n",
    "        _df[f\"style_{s}\"] = (_df.vehicle_style == s).astype(int)\n",
    "        _features.append(f\"style_{s}\")\n",
    "\n",
    "    _features.append(\"msrp\")\n",
    "\n",
    "    _features = list(filter(lambda x: not x.endswith(\"_0\"), _features))\n",
    "\n",
    "    return _df[_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "\n",
    "df = process_features(df_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functional testing\n",
    "\n",
    "# verify if column names are converted to lower case and spaces are replaced with underscores\n",
    "for col in df.columns:\n",
    "    assert col == col.lower().replace(\" \", \"_\")\n",
    "\n",
    "# verify if string columns are converted to lower case and spaces are replaced with underscores\n",
    "string_columns = df.dtypes[df.dtypes == \"object\"].index\n",
    "for col in string_columns:\n",
    "    assert df[col].str.contains(\" \").sum() == 0\n",
    "\n",
    "REQUIRED_FEATURES = [\"engine_hp\", \"engine_cylinders\", \"highway_mpg\", \"city_mpg\", \"popularity\"]\n",
    "REQUIRED_FEATURES += [\"age\"]\n",
    "REQUIRED_FEATURES += [f\"num_doors_{v}\" for v in [2, 3, 4]]\n",
    "REQUIRED_FEATURES += [f\"make_{make}\" for make in MAKES]\n",
    "REQUIRED_FEATURES += [f\"fuel_{fuel}\" for fuel in FUEL_TYPES]\n",
    "REQUIRED_FEATURES += [f\"transmission_{transmission}\" for transmission in TRANSMISSIONS]\n",
    "REQUIRED_FEATURES += [f\"wd_{wd}\" for wd in WD_TYPES]\n",
    "REQUIRED_FEATURES += [f\"cat_{cat}\" for cat in MARKET_CATEGORIES]\n",
    "REQUIRED_FEATURES += [f\"size_{s}\" for s in VEHICLE_SIZES]\n",
    "REQUIRED_FEATURES += [f\"style_{s}\" for s in VEHICLE_STYLES]\n",
    "REQUIRED_FEATURES += [\"msrp\"]\n",
    "\n",
    "REQUIRED_FEATURES = list(filter(lambda x: not x.endswith(\"_0\"), REQUIRED_FEATURES))\n",
    "\n",
    "assert set(df.columns) == set(REQUIRED_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (11914, 129)\n",
      "Index(['engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg',\n",
      "       'popularity', 'age', 'num_doors_2', 'num_doors_3', 'num_doors_4',\n",
      "       'make_chevrolet',\n",
      "       ...\n",
      "       'style_4dr_suv', 'style_passenger_minivan', 'style_cargo_minivan',\n",
      "       'style_crew_cab_pickup', 'style_regular_cab_pickup',\n",
      "       'style_extended_cab_pickup', 'style_2dr_suv', 'style_cargo_van',\n",
      "       'style_convertible_suv', 'style_passenger_van'],\n",
      "      dtype='object', length=128)\n"
     ]
    }
   ],
   "source": [
    "# store feature index for later\n",
    "\n",
    "print(f\"df shape: {df.shape}\")\n",
    "\n",
    "features = list(filter(lambda x: x != \"msrp\", df.columns))\n",
    "features = pd.Index(features)\n",
    "n_features = len(features)\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset split helper\n",
    "\n",
    "def split_dataset(df, val_size=0., test_size=0.2):\n",
    "    \"\"\"Split dataframe (including labels) into train, validation and test sets.\"\"\"\n",
    "    np.random.seed(0)\n",
    "\n",
    "    n = len(df)\n",
    "\n",
    "    n_val, n_test = 0, 0\n",
    "\n",
    "    if val_size > 0:\n",
    "        n_val = int(n * val_size)\n",
    "\n",
    "    if test_size > 0:\n",
    "        n_test = int(n * test_size)\n",
    "\n",
    "    n_train = n - n_val - n_test\n",
    "\n",
    "    idx = np.arange(n)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    df_train = df.iloc[idx[:n_train]]\n",
    "\n",
    "    df_val, df_test = None, None\n",
    "\n",
    "    if n_val > 0:\n",
    "        df_val = df.iloc[idx[n_train:n_train+n_val]]\n",
    "\n",
    "    if n_test > 0:\n",
    "        df_test = df.iloc[idx[n_train+n_val:]]\n",
    "\n",
    "    return df_train, df_val, df_test\n",
    "    \n",
    "\n",
    "def prepare_X_y(df):\n",
    "    \"\"\"Prepare X, y from dataframe. Return as numpy arrays. Convert y to logs.\"\"\"\n",
    "    X = df.drop(\"msrp\", axis=1).values\n",
    "    y = np.log1p(df.msrp.values)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape: (7150, 129)\n",
      "df_val shape: (2382, 129)\n",
      "df_test shape: (2382, 129)\n",
      "X_train shape: (7150, 128)\n",
      "y_train shape: (7150,)\n",
      "X_val shape: (2382, 128)\n",
      "y_val shape: (2382,)\n",
      "X_test shape: (2382, 128)\n",
      "y_test shape: (2382,)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test = split_dataset(df, val_size=0.2, test_size=0.2)\n",
    "\n",
    "print(f\"df_train shape: {df_train.shape}\")\n",
    "print(f\"df_val shape: {df_val.shape}\")\n",
    "print(f\"df_test shape: {df_test.shape}\")\n",
    "\n",
    "X_train, y_train = prepare_X_y(df_train)\n",
    "X_val, y_val = prepare_X_y(df_val)\n",
    "X_test, y_test = prepare_X_y(df_test)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# automatic assertions\n",
    "\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "assert X_val.shape[0] == y_val.shape[0]\n",
    "assert X_test.shape[0] == y_test.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    error = y - y_pred\n",
    "    mse = (error ** 2).mean()\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.0000, rmse: 657216797.36965573\n",
      "alpha: 0.0032, rmse: 0.41809841\n",
      "alpha: 0.0074, rmse: 0.41808765\n",
      "alpha: 0.0128, rmse: 0.41807421\n",
      "alpha: 0.0198, rmse: 0.41805760\n",
      "alpha: 0.0288, rmse: 0.41803733\n",
      "alpha: 0.0405, rmse: 0.41801305\n",
      "alpha: 0.0555, rmse: 0.41798463\n",
      "alpha: 0.0749, rmse: 0.41795244\n",
      "alpha: 0.1000, rmse: 0.41791766\n",
      "alpha: 0.0000, rmse: 657216797.36965573\n",
      "alpha: 0.0324, rmse: 0.41802966\n",
      "alpha: 0.0742, rmse: 0.41795349\n",
      "alpha: 0.1283, rmse: 0.41788659\n",
      "alpha: 0.1981, rmse: 0.41784004\n",
      "alpha: 0.2882, rmse: 0.41782748\n",
      "alpha: 0.4046, rmse: 0.41786374\n",
      "alpha: 0.5550, rmse: 0.41796306\n",
      "alpha: 0.7492, rmse: 0.41813714\n",
      "alpha: 1.0000, rmse: 0.41839421\n",
      "Best alpha: 0.2882 @ RMSE: 0.41782748\n"
     ]
    }
   ],
   "source": [
    "logs = np.logspace(0, 1, num=10, base=10) - 1\n",
    "regularization_params = logs / logs.max()\n",
    "regularization_params = np.hstack([logs / logs.max() * 0.1, logs / logs.max()])\n",
    "\n",
    "scores = []\n",
    "\n",
    "for r in regularization_params:\n",
    "    model = linear_model.Ridge(alpha=r)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # calculate RMSE on validation set\n",
    "    y_hat = model.predict(X_val)\n",
    "    score = rmse(y_val, y_hat)\n",
    "\n",
    "    scores.append({\"alpha\": r, \"rmse\": score})\n",
    "\n",
    "for score in scores:\n",
    "    print(f\"alpha: {score['alpha']:.4f}, rmse: {score['rmse']:.8f}\")\n",
    "\n",
    "r = min(scores, key=lambda x: x[\"rmse\"])[\"alpha\"]\n",
    "\n",
    "print(f\"Best alpha: {r:.4f} @ RMSE: {min(scores, key=lambda x: x['rmse'])['rmse']:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
